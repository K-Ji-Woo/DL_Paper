{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUj6H7h0rQd3"
      },
      "source": [
        "# VGG16을 사용하여 아이돌 이미지 분류\n",
        "- 이미지는 Kaggle에서 다운로드 가능(https://www.kaggle.com/datasets/vkehfdl1/kidf-kpop-idol-dataset-female?resource=download&select=kid_f_train.csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eoO6haA9rAfQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4zzWNNOxo4he"
      },
      "outputs": [],
      "source": [
        "url = './dataset'\n",
        "\n",
        "csv_url_train = url + '/kid_f_train.csv'\n",
        "csv_url_test = url + '/kid_f_test.csv'\n",
        "\n",
        "\n",
        "train_labels = pd.read_csv(csv_url_train)\n",
        "test_labels = pd.read_csv(csv_url_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcyt5Wq-rxBn",
        "outputId": "3a6e0426-77a6-479d-c718-5f60eb72cca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 데이터셋 shape >  (5591, 2)\n",
            "훈련 데이터셋 비율 top 5\n",
            "name\n",
            "lisa        22.929708\n",
            "rose        22.267931\n",
            "jisoo       18.297263\n",
            "jennie       7.404758\n",
            "kimminju     4.668217\n",
            "dtype: float64\n",
            "\n",
            "테스트 데이터셋 shape >  (300, 2)\n",
            "테스트 데이터셋 비율 top 5\n",
            "name\n",
            "jisoo     24.000000\n",
            "iu        21.333333\n",
            "rose      14.000000\n",
            "lisa      13.333333\n",
            "jennie     5.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 라벨값 비율 확인\n",
        "print('훈련 데이터셋 shape > ', train_labels.shape)\n",
        "print('훈련 데이터셋 비율 top 5')\n",
        "print((train_labels.groupby('name').size() / train_labels.shape[0] * 100).sort_values(ascending=False).head(5))\n",
        "\n",
        "print('\\n테스트 데이터셋 shape > ', test_labels.shape)\n",
        "print('테스트 데이터셋 비율 top 5')\n",
        "print((test_labels.groupby('name').size() / test_labels.shape[0] * 100).sort_values(ascending=False).head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkl4g1hAr2w4"
      },
      "source": [
        "# 데이터 전처리\n",
        "- 훈련 데이터셋 중 lisa, rose, jisoo의 비율이 절반 이상이 넘음 => 따라서 세 명은 훈련 데이터, 학습 데이터에서 삭제\n",
        "- 텐서화 \n",
        " - 세명의 데이터를 삭제한 데이프레임을 기준으로 이미지 불러와서 텐서화\n",
        " - 이미지파일만 있는 것이 아니라 \n",
        " Thumbs.db' 파일도 있으므로 텐서로 변활할 때 에러 발생이 예상되므로 예외처리 하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KKfMaZbnLn2m"
      },
      "outputs": [],
      "source": [
        "# 리사, 로제, 지수 제거\n",
        "drop_name = ['lisa', 'rose', 'jisoo']\n",
        "\n",
        "train_drop_index = train_labels[train_labels['name'].isin(drop_name)].index\n",
        "test_drop_index = test_labels[test_labels['name'].isin(drop_name)].index\n",
        "\n",
        "train_labels = train_labels.drop(train_drop_index)\n",
        "test_labels = test_labels.drop(test_drop_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYyZOQBgZV7p",
        "outputId": "bfd8fec1-66fd-46b3-9b4d-9186bb2a3a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###### 세 명 삭제 후 ######\n",
            "train_labels 데이터 개수 :  2041\n",
            "train_labels 클래스 개수 :  52\n",
            "------------------------------\n",
            "test_labels 데이터 개수 :  146\n",
            "test_labels클래스 개수 :  22\n"
          ]
        }
      ],
      "source": [
        "print(\"###### 세 명 삭제 후 ######\")\n",
        "print(\"train_labels 데이터 개수 : \", len(train_labels))\n",
        "print(\"train_labels 클래스 개수 : \", len(train_labels['name'].unique()))\n",
        "print('----------' * 3)\n",
        "print(\"test_labels 데이터 개수 : \", len(test_labels))\n",
        "print(\"test_labels클래스 개수 : \", len(test_labels['name'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FGNBFyDzXQ9a"
      },
      "outputs": [],
      "source": [
        "def image_to_tensor(df, dir_url):\n",
        "    file_list = os.listdir(dir_url)\n",
        "    result_list = []\n",
        "\n",
        "    for i in tqdm(range(df.shape[0])):\n",
        "        try:\n",
        "            file_name = df['file_name'].iloc[i] # 파일 이름 Ex)100.jpg\n",
        "            label = df['name'].iloc[i] # 연예인 이름\n",
        "\n",
        "            # 이미지 오픈 및 텐서화\n",
        "            file_url = dir_url + '/' + file_name\n",
        "            img = Image.open(file_url)\n",
        "            tf = transforms.ToTensor()\n",
        "            tensor_img = tf(img)\n",
        "            # 튜플 형태로 저장\n",
        "            result_list.append((tensor_img, label))\n",
        "        except:\n",
        "            print(\"파일명 > \", file_name, \"\\n연예인명 > \", label)\n",
        "            \n",
        "    return result_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "hZBN6UdAX1Pj",
        "outputId": "6b46b8fe-ae04-41aa-cc13-029eef987a7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2041/2041 [00:29<00:00, 69.86it/s] \n",
            " 67%|██████▋   | 98/146 [00:00<00:00, 121.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일명 >  1792 .jpg \n",
            "연예인명 >  joyuri\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 83.00it/s]\n"
          ]
        }
      ],
      "source": [
        "train_dir_url = './dataset/HQ_512x512/HQ_512x512' \n",
        "test_dir_url = './dataset/test_final_with_degrad/test'\n",
        "\n",
        "train_dataset = image_to_tensor(train_labels, train_dir_url)\n",
        "test_dataset = image_to_tensor(test_labels, test_dir_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5xP3ZHfi5QWc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dataset 데이터 개수 :  2041\n",
            "train_dataset 라벨 개수 52\n",
            "------------------------------\n",
            "test_dataset 데이터 개수 :  145\n",
            "test_dataset 라벨 개수 22\n"
          ]
        }
      ],
      "source": [
        "print(\"train_dataset 데이터 개수 : \", len(train_dataset))\n",
        "\n",
        "lst = []\n",
        "for i in range(len(train_dataset)):\n",
        "    lst.append(train_dataset[i][1])\n",
        "s_lst = pd.Series(lst)\n",
        "print('train_dataset 라벨 개수', len(s_lst.unique()))\n",
        "\n",
        "print('----------' * 3)\n",
        "\n",
        "print(\"test_dataset 데이터 개수 : \", len(test_dataset))\n",
        "\n",
        "lst = []\n",
        "for i in range(len(test_dataset)):\n",
        "    lst.append(test_dataset[i][1])\n",
        "s_lst = pd.Series(lst)\n",
        "print('test_dataset 라벨 개수', len(s_lst.unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zhRXRwKJCdW"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qLt8WnMLcnLs"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L6N6OKWMJCaG"
      },
      "outputs": [],
      "source": [
        "# DataLoader 만들기\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_laoder = DataLoader(dataset=test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VGG 모델은 여러가지 타입이 있으므로 타입에 맞춰 모델 생성하기 위해 layer를 거친 후 출력 kernel의 개수 미리 지정(M은 pooling layer)\n",
        "VGG_types = {\n",
        "    'VGG11' : [64, 'M', 128, 'M', 256,256, 'M', 512,512, 'M',512,512,'M'],\n",
        "    'VGG13' : [64,64, 'M', 128, 128, 'M', 256, 256, 'M', 512,512, 'M', 512,512,'M'],\n",
        "    'VGG16' : [64,64, 'M', 128, 128, 'M', 256, 256,256, 'M', 512,512,512, 'M',512,512,512,'M'],\n",
        "    'VGG19' : [64,64, 'M', 128, 128, 'M', 256, 256,256,256, 'M', 512,512,512,512, 'M',512,512,512,512,'M']\n",
        "}\n",
        "\n",
        "def make_layer(config): # 위에서 정의한 타입별로 모델 생성\n",
        "    layers = []\n",
        "    in_planes = 3 # input 개수\n",
        "    for value in config: \n",
        "        if value == \"M\": # Pooling layer 일 때\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        else: # Conv layer 일 때\n",
        "            layers.append(nn.Conv2d(in_planes, value, kernel_size=3, padding=1)) \n",
        "            layers.append(nn.ReLU())\n",
        "            in_planes = value\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G4bj0-3OJCWP"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init(self, config, num_class=52): # model : 만들 VGG 모델 형태 \n",
        "        super(VGG, self).__init__()\n",
        "        self.features = make_layer(config)\n",
        "        \n",
        "        # Fully Connected Layer 쌓기\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "    \n",
        "    # 학습\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = torch.flatten(out,1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9ojzRlUaJCSo"
      },
      "outputs": [],
      "source": [
        "def VGG11():\n",
        "    return VGG(config=VGG_types['VGG11'])\n",
        "\n",
        "def VGG13():\n",
        "    return VGG(config=VGG_types['VGG13'])\n",
        "\n",
        "def VGG16():\n",
        "    return VGG(config=VGG_types['VGG16'])\n",
        "\n",
        "def VGG19():\n",
        "    return VGG(config=VGG_types['VGG19'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of4rtZbWJCPM"
      },
      "outputs": [],
      "source": [
        "model = VGG11()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEw0ldskJB4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IASuJLl7JB0o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF50T6qLJBwy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXjkOpKkr1-B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klns2e05r15k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjOpGZ9-r11a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzjHOP8jr1w-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSVGtOqrr1sK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VieFsK7zr1np"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUZND3m2r1iz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPHkvgLqr1eH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XxfNdHHr1Ts"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
